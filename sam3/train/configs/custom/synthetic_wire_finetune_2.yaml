# @package _global_
defaults:
  - /configs/eval_base.yaml
  - _self_

# -----------------------------------------------------------------------------
# Paths
# -----------------------------------------------------------------------------
paths:
  checkpoint_path: null
  bpe_path: /home/daizi/sam3/sam3/assets/bpe_simple_vocab_16e6.txt.gz
  experiment_log_dir: /home/daizi/sam3/outputs/synthetic_wire_finetune_4

  data_root: ${oc.env:HOME}/data/synthetic_wire
  img_path: ${paths.data_root}
  train_coco_gt: ${paths.data_root}/train.json
  valid_coco_gt: ${paths.data_root}/valid.json
  test_coco_gt: ${paths.data_root}/test.json

# -----------------------------------------------------------------------------
# Scratch (hyperparams / transforms)
# -----------------------------------------------------------------------------
scratch:
  # ---- dataset / io ----
  # keep your presence eval behavior (matches eval_base)
  use_presence_eval: true

  # ---- image sizes ----
  # eval_base sets resolution: 1008; keep unless you have a reason to change
  resolution: 1008

  # ---- dataloader ----
  train_batch_size: 1
  val_batch_size: 1
  test_batch_size: 1
  num_train_workers: 8
  num_val_workers: 8
  num_test_workers: 8
  hybrid_repeats: 1

  # ---- normalization ----
  train_norm_mean: [0.5, 0.5, 0.5]
  train_norm_std:  [0.5, 0.5, 0.5]
  val_norm_mean:   [0.5, 0.5, 0.5]
  val_norm_std:    [0.5, 0.5, 0.5]

  # ---- stability / NaN control knobs (LR & schedule) ----
  # Official eval_base defines lr_* from lr_scale (and schedulers use those). :contentReference[oaicite:3]{index=3}
  # If you're getting NaNs in out_bbox/out_score, LOWER this first.
  lr_scale: 0.02          # was 0.1 in eval_base
  scheduler_timescale: 20
  scheduler_warmup: 200   # was 20 in eval_base; longer warmup often helps stability
  scheduler_cooldown: 20
  wd: 0.1
  lrd_vision_backbone: 0.9

  # ---- transforms ----
  # IMPORTANT: DecodeRle must come BEFORE any resize/pad that touches masks.
  base_train_transform:
    - _target_: sam3.train.transforms.basic_for_api.ComposeAPI
      transforms:
        - _target_: sam3.train.transforms.segmentation.DecodeRle

        - _target_: sam3.train.transforms.basic_for_api.RandomResizeAPI
          sizes:
            _target_: sam3.train.transforms.basic.get_random_resize_scales
            size: ${scratch.resolution}
            min_size: 480
            rounded: false
          max_size:
            _target_: sam3.train.transforms.basic.get_random_resize_max_size
            size: ${scratch.resolution}
          square: true
          consistent_transform: false

        - _target_: sam3.train.transforms.basic_for_api.PadToSizeAPI
          size: ${scratch.resolution}
          consistent_transform: false

        - _target_: sam3.train.transforms.basic_for_api.ToTensorAPI
        - _target_: sam3.train.transforms.basic_for_api.NormalizeAPI
          mean: ${scratch.train_norm_mean}
          std: ${scratch.train_norm_std}

  # Deterministic val transform, still decodes RLE (fixes your KeyError)
  base_val_transform:
    - _target_: sam3.train.transforms.basic_for_api.ComposeAPI
      transforms:
        - _target_: sam3.train.transforms.segmentation.DecodeRle

        - _target_: sam3.train.transforms.basic_for_api.RandomResizeAPI
          sizes: ${scratch.resolution}
          max_size:
            _target_: sam3.train.transforms.basic.get_random_resize_max_size
            size: ${scratch.resolution}
          square: true
          consistent_transform: false

        - _target_: sam3.train.transforms.basic_for_api.PadToSizeAPI
          size: ${scratch.resolution}
          consistent_transform: false

        - _target_: sam3.train.transforms.basic_for_api.ToTensorAPI
        - _target_: sam3.train.transforms.basic_for_api.NormalizeAPI
          mean: ${scratch.val_norm_mean}
          std: ${scratch.val_norm_std}

  # Minimal test/inference transform (no GT mask needed)
  base_test_transform:
    - _target_: sam3.train.transforms.basic_for_api.ComposeAPI
      transforms:
        - _target_: sam3.train.transforms.basic_for_api.RandomResizeAPI
          sizes: ${scratch.resolution}
          max_size:
            _target_: sam3.train.transforms.basic.get_random_resize_max_size
            size: ${scratch.resolution}
          square: true
          consistent_transform: true
        - _target_: sam3.train.transforms.basic_for_api.ToTensorAPI
        - _target_: sam3.train.transforms.basic_for_api.NormalizeAPI
          mean: ${scratch.val_norm_mean}
          std: ${scratch.val_norm_std}

  # ---- collators ----
  collate_fn_train:
    _target_: sam3.train.data.collator.collate_fn_api
    _partial_: true
    repeats: ${scratch.hybrid_repeats}
    dict_key: all
    with_seg_masks: true

  collate_fn_val:
    _target_: sam3.train.data.collator.collate_fn_api
    _partial_: true
    repeats: ${scratch.hybrid_repeats}
    dict_key: synthetic_wire
    with_seg_masks: true

  collate_fn_test:
    _target_: sam3.train.data.collator.collate_fn_api
    _partial_: true
    repeats: 1
    dict_key: synthetic_wire
    with_seg_masks: false

  # ---- matcher ----
  matcher:
    _target_: sam3.train.matcher.BinaryHungarianMatcherV2
    focal: true
    cost_class: 2.0
    cost_bbox: 5.0
    cost_giou: 2.0
    alpha: 0.25
    gamma: 2
    stable: false

  # ---- postproc (used by PredictionDumper) ----
  mask_postprocessor_thresholded:
    detection_threshold: 0.3
    always_interpolate_masks_on_gpu: false

# -----------------------------------------------------------------------------
# Trainer
# -----------------------------------------------------------------------------
trainer:
  mode: train
  max_epochs: 5
  accelerator: cuda
  seed_value: 123

  skip_saving_ckpts: false
  skip_first_val: false
  val_epoch_freq: 1
  empty_gpu_mem_cache_after_eval: false

  distributed:
    backend: nccl
    find_unused_parameters: true
    gradient_as_bucket_view: true

  model:
    _target_: sam3.model_builder.build_sam3_image_model
    bpe_path: ${paths.bpe_path}
    checkpoint_path: ${paths.checkpoint_path}
    device: cuda
    eval_mode: false
    enable_segmentation: true

  data:
    train:
      _target_: sam3.train.data.torch_dataset.TorchDataset
      dataset:
        _target_: sam3.train.data.sam3_image_dataset.Sam3ImageDataset
        coco_json_loader:
          _target_: sam3.train.data.coco_json_loaders.COCO_FROM_JSON
          # prompts is eval()'d by the loader, so keep it a string. :contentReference[oaicite:4]{index=4}
          prompts: |
            [{"id": 1, "name": "cable"}]
          include_negatives: true
          category_chunk_size: 8
          _partial_: true
        img_folder: ${paths.img_path}
        ann_file: ${paths.train_coco_gt}
        transforms: ${scratch.base_train_transform}
        load_segmentation: true
        max_ann_per_img: 200
        multiplier: 1
        training: true
      shuffle: true
      batch_size: ${scratch.train_batch_size}
      num_workers: ${scratch.num_train_workers}
      pin_memory: false
      drop_last: false
      collate_fn: ${scratch.collate_fn_train}

    val:
      _target_: sam3.train.data.torch_dataset.TorchDataset
      dataset:
        _target_: sam3.train.data.sam3_image_dataset.Sam3ImageDataset
        coco_json_loader:
          _target_: sam3.train.data.coco_json_loaders.COCO_FROM_JSON
          prompts: |
            [{"id": 1, "name": "cable"}]
          include_negatives: true
          category_chunk_size: 8
          _partial_: true
        img_folder: ${paths.img_path}
        ann_file: ${paths.valid_coco_gt}
        transforms: ${scratch.base_val_transform}
        load_segmentation: true
        max_ann_per_img: 200
        multiplier: 1
        training: false
      shuffle: false
      batch_size: ${scratch.val_batch_size}
      num_workers: ${scratch.num_val_workers}
      pin_memory: false
      drop_last: false
      collate_fn: ${scratch.collate_fn_val}

    # Optional: inference-only test loader (no GT masks loaded)
    test:
      _target_: sam3.train.data.torch_dataset.TorchDataset
      dataset:
        _target_: sam3.train.data.sam3_image_dataset.Sam3ImageDataset
        coco_json_loader:
          _target_: sam3.train.data.coco_json_loaders.COCO_FROM_JSON
          prompts: |
            [{"id": 1, "name": "cable"}]
          include_negatives: false
          category_chunk_size: 8
          _partial_: true
        img_folder: ${paths.img_path}
        ann_file: ${paths.test_coco_gt}
        transforms: ${scratch.base_test_transform}
        load_segmentation: false
        max_ann_per_img: 200
        multiplier: 1
        training: false
      shuffle: false
      batch_size: ${scratch.test_batch_size}
      num_workers: ${scratch.num_test_workers}
      pin_memory: false
      drop_last: false
      collate_fn: ${scratch.collate_fn_test}

  # -----------------------------------------------------------------------------
  # OPTIM (LR is controlled by scratch.lr_scale -> scratch.lr_transformer etc). :contentReference[oaicite:5]{index=5}
  # -----------------------------------------------------------------------------
  optim:
    amp:
      enabled: false
      amp_dtype: bfloat16

    optimizer:
      _target_: torch.optim.AdamW

    gradient_clip:
      _target_: sam3.train.optim.optimizer.GradientClipper
      max_norm: 0.1
      norm_type: 2

    param_group_modifiers:
      - _target_: sam3.train.optim.optimizer.layer_decay_param_modifier
        _partial_: true
        layer_decay_value: ${scratch.lrd_vision_backbone}
        apply_to: 'backbone.vision_backbone.trunk'
        overrides:
          - pattern: '*pos_embed*'
            value: 1.0

    options:
      lr:
        - scheduler:
            _target_: sam3.train.optim.schedulers.InverseSquareRootParamScheduler
            base_lr: ${scratch.lr_transformer}
            timescale: ${scratch.scheduler_timescale}
            warmup_steps: ${scratch.scheduler_warmup}
            cooldown_steps: ${scratch.scheduler_cooldown}
        - scheduler:
            _target_: sam3.train.optim.schedulers.InverseSquareRootParamScheduler
            base_lr: ${scratch.lr_vision_backbone}
            timescale: ${scratch.scheduler_timescale}
            warmup_steps: ${scratch.scheduler_warmup}
            cooldown_steps: ${scratch.scheduler_cooldown}
          param_names:
            - 'backbone.vision_backbone.*'
        - scheduler:
            _target_: sam3.train.optim.schedulers.InverseSquareRootParamScheduler
            base_lr: ${scratch.lr_language_backbone}
            timescale: ${scratch.scheduler_timescale}
            warmup_steps: ${scratch.scheduler_warmup}
            cooldown_steps: ${scratch.scheduler_cooldown}
          param_names:
            - 'backbone.language_backbone.*'

      weight_decay:
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: ${scratch.wd}
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.0
          param_names:
            - '*bias*'
          module_cls_names: ['torch.nn.LayerNorm']

  # -----------------------------------------------------------------------------
  # LOSS (edit weights here)
  # -----------------------------------------------------------------------------
  loss:
    all:
      _target_: sam3.train.loss.sam3_loss.Sam3LossWrapper
      matcher: ${scratch.matcher}

      # one-to-many matcher (keep but lighter)
      o2m_weight: 1.0
      o2m_matcher:
        _target_: sam3.train.matcher.BinaryOneToManyMatcher
        alpha: 0.3
        threshold: 0.4
        topk: 4
      use_o2m_matcher_on_o2m_aux: false

      loss_fns_find:
        - _target_: sam3.train.loss.loss_fns.Boxes
          weight_dict:
            loss_bbox: 1.0
            loss_giou: 1.0

        - _target_: sam3.train.loss.loss_fns.IABCEMdetr
          weak_loss: false
          weight_dict:
            loss_ce: 20.0
            presence_loss: 20.0
          pos_weight: 10.0
          alpha: 0.25
          gamma: 2
          use_presence: true
          pos_focal: false
          pad_n_queries: 200
          pad_scale_pos: 1.0

        # Instance seg: you can reduce these if training blows up (NaNs).
        - _target_: sam3.train.loss.loss_fns.Masks
          focal_alpha: 0.25
          focal_gamma: 2.0
          weight_dict:
            loss_mask: 50.0   # was 200.0 in your config
            loss_dice: 5.0    # was 10.0
          compute_aux: false

      loss_fn_semantic_seg: null
      scale_by_find_batch_size: true

    default:
      _target_: sam3.train.loss.sam3_loss.DummyLoss

  # -----------------------------------------------------------------------------
  # METERS (dump + offline coco eval)
  # -----------------------------------------------------------------------------
  meters:
    val:
      synthetic_wire:
        segm:
          _target_: sam3.eval.coco_writer.PredictionDumper
          iou_type: "segm"
          dump_dir: ${launcher.experiment_log_dir}/dumps/synthetic_wire
          merge_predictions: true
          postprocessor: ${scratch.mask_postprocessor_thresholded}
          gather_pred_via_filesys: ${scratch.gather_pred_via_filesys}
          maxdets: 100
          pred_file_evaluators:
            - _target_: sam3.eval.coco_eval_offline.CocoEvaluatorOfflineWithPredFileEvaluators
              gt_path: ${paths.valid_coco_gt}
              tide: false
              iou_type: "segm"

  checkpoint:
    save_dir: ${launcher.experiment_log_dir}/checkpoints
    save_freq: 1

  logging:
    log_dir: ${launcher.experiment_log_dir}/logs/
    log_freq: 10
    log_scalar_frequency: 20
    tensorboard_writer:
      _target_: sam3.train.utils.logger.make_tensorboard_logger
      log_dir: ${launcher.experiment_log_dir}/tensorboard
      flush_secs: 120
      should_log: true
    wandb_writer: null

# -----------------------------------------------------------------------------
# Local run (no slurm)
# -----------------------------------------------------------------------------
launcher:
  num_nodes: 1
  gpus_per_node: 1
  experiment_log_dir: ${paths.experiment_log_dir}
  multiprocessing_context: forkserver

submitit:
  use_cluster: false
  account: null
  partition: null
  qos: null
  timeout_hour: 72
  cpus_per_task: 10
  port_range: [10000, 65000]
  constraint: null